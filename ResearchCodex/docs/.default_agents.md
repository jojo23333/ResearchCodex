# ResearchCodex Agents Guide

**Goal:** help a human scientist quickly **prototype and verify research ideas** using the `rcodex` layout.

---
## 1. Always get context from `.rcodex/config.yaml`

Before doing anything:
Use rcodex status to get current working status.

- Read `.rcodex/config.yaml`:

```yaml
current_project: <string or null>
current_idea: <string or null> 
mode: plan/implement
```

- If `current_project` or `current_idea` is `null`, ask the human to run `rcodex project create/switch` or `rcodex idea create`.
- For PLAN mode, you will work in `projects/<current_project>/<current_idea>`
- For IMPLEMENT mode you will reference `projects/<current_project>/<current_idea>` work on 1. Shared code folder `srcs/` 2. Idea-specific scripts go in `experiments/<current_project>/`.

---

## 2. Operating Modes

You have **two modes**:

1. **PLAN mode** – only touch markdown in the idea folder.
2. **IMPLEMENT mode** – create/modify code + tests + implementation docs.

Mode selection is through reading the mode field in .rcodex/config.yaml
IF the 

---

## 3. PLAN Mode

PLAN mode has **two stages**:

### 3.1 Stage 1 – Idea Formation (`idea_ai.md`)

**Goal:** turn a rough idea into a detailed, reviewable **AI-elaborated idea**.

Steps:

1. Ensure `IDEA_MD` exists.
   - If missing, create a minimal template and ask the human to fill in a short summary.
2. Read `IDEA_MD` (human draft) and any useful context under `projects/<current_project>/context/` (optional).
3. Ask **clarifying questions** via {{CLARIFICATION_CHANNEL_TBD}}:
   - Data: which dataset(s), where stored (e.g. `{{DATA_ROOT}}`), allowed subsets.
   - Models: families / checkpoints / framework (PyTorch, etc.).
   - Compute constraints: GPUs / time budget.
   - Evaluation: key metrics and baselines.
   - Libraries / licensing / privacy constraints.
4. Rewrite everything into `IDEA_AI_MD` as a **structured document**:


- Be concrete, but mark assumptions and unknowns with placeholders:
  - `{{DATA_ROOT}}`, `{{PRIMARY_METRIC}}`, `{{ASSUMED_DATASET: CIFAR-10}}`, etc.

### 3.2 Stage 2 – Plan Formation (`plans.md`)

**Goal:** convert `idea_ai.md` into a concrete **implementation plan**.

Steps:

1. Read `IDEA_AI_MD` and existing `PLANS_MD` (if any).
2. Write/update `PLANS_MD` as a concise task list:

Suggested structure:

```markdown
```

3. Keep tasks **small and actionable**.  
4. You will later mark tasks as done / modified during implementation.

---

## 4. IMPLEMENT Mode

IMPLEMENT mode turns plans into real code and documentation.

### 4.1 Preconditions

Only enter IMPLEMENT mode when:

- `current_project` and `current_idea` are set.
- `IDEA_AI_MD` and `PLANS_MD` exist and are reasonably complete.
- The human has signaled “OK to implement” ({{IMPLEMENT_APPROVAL_TBD}}).

If not, go back to PLAN mode.

### 4.2 Where to put code

- **Shared utilities** → `srcs/` (reusable across projects/ideas).
- **Idea-specific code** → `experiments/<current_project>/`:

```text
experiments/<current_project>/<idea_slug>_train.py
experiments/<current_project>/<idea_slug>_eval.py
experiments/<current_project>/<idea_slug>_config.yaml
```

Exact naming convention is {{IDEA_SCRIPT_NAMING_TBD}}, but include the idea slug or a short unique alias.

### 4.3 Implementation loop

For each implementation session:

1. Reload `.rcodex/config.yaml`, `IDEA_MD`, `IDEA_AI_MD`, `PLANS_MD`.
2. Choose a not-yet-done task from `PLANS_MD` (respect dependencies & human priorities).
3. Implement the task:
   - Create/modify files under `srcs/` and `experiments/<current_project>/`.
   - Use clear functions, docstrings, and simple entrypoints.
4. Add **basic tests** for new behavior:
   - Place them under {{TEST_DIR_TBD}}.
   - Use small synthetic data or small dataset subsets.
5. If possible, run tests via {{TEST_COMMAND_TBD}}.
   - If you cannot run them, document how to run them.
6. Update `PLANS_MD`:
   - Mark tasks as done or partially done.
   - Note any deviations:
     - `Implementation note: originally planned X, implemented Y because Z.`

### 4.4 Implementation doc (`implementation.md`)

For each substantial implementation step, update `IMPL_MD` in the idea folder (or whatever filename we finalize later).

Suggested structure:

```markdown
# Implementation Report: {{IDEA_TITLE}}

Project: {{current_project}}
Idea path: {{current_idea}}
Last AI update: {{NOW_TBD}}

## Summary
What was implemented.

## Code Changes
- srcs/{{module}}: ...
- experiments/{{project}}/{{script}}: ...

## How to Run
- Environment: {{ENV_REQUIREMENTS_TBD}}
- Train: {{TRAIN_COMMAND_EXAMPLE}}
- Eval: {{EVAL_COMMAND_EXAMPLE}}

## Tests
- Added: {{TEST_FILES_LIST}}
- Run via: {{TEST_COMMAND_TBD}}
- Status: {{TEST_STATUS_TBD}}

## Deviations from Plan
- Reference T-IDs from plans.md and explain changes.

## Known Issues / TODO
- ...
```

This document is the **primary factual record** for future debugging and reuse.

---

## 5. Debugging & Self-Checks

- Always try to generate at least **smoke tests** for new code.
- Prefer fast tests that:
  - Use tiny data.
  - Run in seconds.
- If a test fails and you can’t fully fix it:
  - Document the failure in `IMPL_MD`.
  - Add / update a task in `PLANS_MD` (e.g., `T-105: fix failing test {{TEST_NAME}}`).

---

## 6. Placeholders to be defined later

These tokens mark things a human or future config must decide:

- `{{MODE_SELECTION_TBD}}` – how PLAN vs IMPLEMENT is chosen.
- `{{CLARIFICATION_CHANNEL_TBD}}` – how you ask questions (chat, comments, etc.).
- `{{IMPLEMENT_APPROVAL_TBD}}` – how human says “go ahead and implement”.
- `{{IDEA_SCRIPT_NAMING_TBD}}` – final naming scheme for experiment scripts.
- `{{TEST_DIR_TBD}}` – location for tests.
- `{{TEST_COMMAND_TBD}}` – how to run the full test suite.
- `{{DATA_ROOT}}`, `{{CHECKPOINT_DIR}}`, `{{PRIMARY_METRIC}}`, etc. – environment- and project-specific paths/settings.

Always follow the **spirit** of this guide, and clearly mark any assumptions with `{{...}}` so the human can review and adjust.